Metadata-Version: 2.4
Name: book-recommendation-engine
Version: 0.1.0
Summary: Book recommendation engine with AI
Author-email: Dan Guilliams <dan.guilliams@danguilliams.com>
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi
Requires-Dist: uvicorn[standard]
Requires-Dist: langchain
Requires-Dist: langchain-openai
Requires-Dist: langchain-community
Requires-Dist: langgraph
Requires-Dist: openai>=1.10.0
Requires-Dist: mcp
Requires-Dist: fastmcp
Requires-Dist: langchain-mcp-adapters
Requires-Dist: sqlalchemy[asyncio]
Requires-Dist: asyncpg>=0.29.0
Requires-Dist: psycopg2-binary
Requires-Dist: aiokafka>=0.9.0
Requires-Dist: pandas
Requires-Dist: faiss-cpu
Requires-Dist: textstat>=0.7.3
Requires-Dist: aiohttp>=3.9.1
Requires-Dist: asyncio-throttle
Requires-Dist: pydantic>=2.5.0
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: streamlit>=1.28.1
Requires-Dist: requests>=2.31.0
Requires-Dist: typer
Requires-Dist: rich

# Book Recommendation Engine

## 1  Vectorâ€‘store & Database decision tables

### 1.1 Vector stores

| Store        | Pros                                                                                  | Cons                                                                  | Freeâ€‘tier viability        | Ease of swap                       | Scaling notes                             | **Demo Suitability (1â€‘5)** |
| ------------ | ------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | -------------------------- | ---------------------------------- | ----------------------------------------- | -------------------------- |
| **FAISS**    | â€¢ Inâ€‘process, zero network latency<br>â€¢ No account/keys<br>â€¢ Mature LangChain wrapper | â€¢ Singleâ€‘node only (RAMâ€‘bound)<br>â€¢ No persistence without extra work | âœ… fully local              | Very high â€“ just replace file path | Scaleâ€‘up (larger RAM) or shard behind API | **5**                      |
| **Chroma**   | â€¢ Local *or* clientâ€‘server modes<br>â€¢ Builtâ€‘in persistence                            | â€¢ Earlyâ€‘stage, smaller community<br>â€¢ Docker image adds 500 MB        | âœ… local â†’ free             | High â€“ single URL switch           | Horizontal scaling experimental           | 4                          |
| **Pinecone** | â€¢ Fully managed, automatic sharding<br>â€¢ Production SLA                               | â€¢ Network latency<br>â€¢ APIâ€‘key management<br>â€¢ Paid beyond hobby tier | Limited â€“ 5 k vectors free | Medium â€“ swap env + install SDK    | Effortless horizontal scale               | 3                          |

### 1.2 Databases

| DB           | Pros                                                         | Cons                                                             | Freeâ€‘tier viability | Ease of swap                 | Scaling notes                    | **Demo Suitability (1â€‘5)** |
| ------------ | ------------------------------------------------------------ | ---------------------------------------------------------------- | ------------------- | ---------------------------- | -------------------------------- | -------------------------- |
| **SQLite**   | â€¢ Zero install, single file<br>â€¢ ACID, full SQL              | â€¢ Singleâ€‘writer lock<br>â€¢ No native JSON indexes                 | âœ… infinite          | Very high â€“ change URI       | Vertical only; good backup story | 4                          |
| **Postgres** | â€¢ Rich SQL + JSONB<br>â€¢ Great LangChain + SQLAlchemy support | â€¢ Requires service container<br>â€¢ Slightly heavier RAM (â‰ˆ200 MB) | âœ… docker, free      | High â€“ change URI and driver | Horizontal via readâ€‘replicas     | **5**                      |
| **InfluxDB** | â€¢ Timeâ€‘series firstâ€‘class<br>â€¢ Good for metrics              | â€¢ Poor relational joins<br>â€¢ Extra query language                | Limited OSS         | Low â€“ different query model  | Scales well for metrics only     | 3                          |

### 1.3 Chosen stack (â‰¤150 words)

A singleâ€‘school deployment needs **low latency, zero external dependencies, and smooth developer ergonomics**.
**FAISS** scores highest because it is inâ€‘process, free, and trivial to vendorâ€‘in; durability is solved by writing the FAISS index to the shared `vector_store/` volume after each ingest run.
For the relational layer, **Postgres** wins: we already spin up Kafka and multiple microâ€‘services â€“ adding one lightweight Postgres container costs little but unlocks concurrent writes, JSONB columns for flexible catalog metadata, and future migration paths (RDS, Cloud SQL) with no code changes.
Both choices swap cleanly via `.env` edits (`VECTOR_STORE_TYPE`, `DB_URL`).

---

## 2  Mermaid architecture diagram

```mermaid
flowchart LR
    subgraph Ingestion_Service
        A1[CSV Watcher] --> A2[Vector Embed & Upsert (FAISS)]
        A1 --> A3[Relational Upsert (Postgres)]
        A1 --> A4[Kafka Producer<br>metrics.topic]
    end

    subgraph Recommendation_API
        B1[/FastAPI/] -->|spawn| B2[FastMCP registry<br>(stdio)]
        B1 --> B3[LangGraph flow<br>(GPTâ€‘4o)]
        B1 --> B4[Kafka Producer]
    end

    subgraph Streamlit_UI
        C1[streamlit app.py] -->|REST| B1
    end

    subgraph Metrics_Consumer
        D1[Kafka Consumer] --> D2[Structured log writer]
    end

    subgraph Optional_Stubs
        E1[TTS_Worker]:::stub
        E2[Image_Worker]:::stub
    end

    subgraph Offline
        W1[Book Enrichment] --> Postgres
        W2[Graph Refresher] --> Postgres
        W2 --> Kafka((graph_delta))
    end

    Postgres[(Postgres)]
    FAISS[(FAISS index)]
    ZK[(ZooKeeper)]
    Kafka[(Kafka Broker)]

    A2 --> FAISS
    B3 --> FAISS
    A3 --> Postgres
    B3 --> Postgres
    A4 --> Kafka
    B4 --> Kafka
    Kafka --> D1
    ZK --coord--> Kafka

    classDef stub stroke-dasharray: 5 5,color:#999
```

---

## 3  Directory tree

```text
C:\Users\Dan Guilliams\OneDrive\Code Projects\book_recommendation_engine
â”‚  docker-compose.yml
â”‚  .env.template
â”‚  README.md
â””â”€src
    â”œâ”€common
    â”‚      __init__.py
    â”‚      settings.py
    â”‚      models.py
    â”‚      logging.py
    â”œâ”€ingestion_service
    â”‚      __init__.py
    â”‚      main.py
    â”‚      Dockerfile
    â”œâ”€recommendation_api
    â”‚      __init__.py
    â”‚      main.py
    â”‚      mcp_book_server.py
    â”‚      db_models.py
    â”‚      Dockerfile
    â”‚      â””â”€tools
    â”‚             __init__.py
    â”‚             fetch_google_books_meta.py
    â”‚             fetch_open_library_meta.py
    â”‚             readability_formula_estimator.py
    â”‚             compute_student_reading_level.py
    â”œâ”€streamlit_ui
    â”‚      __init__.py
    â”‚      app.py
    â”‚      Dockerfile
    â”œâ”€metrics_consumer
    â”‚      __init__.py
    â”‚      main.py
    â”‚      Dockerfile
    â”œâ”€log_consumer
    â”‚      __init__.py
    â”‚      main.py
    â”‚      Dockerfile
    â”œâ”€graph_refresher
    â”‚      __init__.py
    â”‚      main.py
    â”‚      Dockerfile
    â”œâ”€book_enrichment_worker
    â”‚      __init__.py
    â”‚      main.py
    â”‚      Dockerfile
    â””â”€stubs
        â”œâ”€tts_worker
        â”‚      __init__.py
        â”‚      main.py
        â”‚      Dockerfile
        â”‚      README.md
        â””â”€image_worker
               __init__.py
               main.py
               Dockerfile
               README.md
```

---

## 4  Quick Start

The system now includes:
- **Full PostgreSQL schema** (auto-executed on container boot)
- **Realistic sample data** (3 books, 3 students, 5 checkouts)
- **Cron-scheduled workers** (enrichment at 01:00, graph refresh at 02:00)

```bash
# one-liner to bring up stack, load sample data, and schedule workers
docker compose up --build
```

Workers use **supercronic** so the enrichment runs at **01:00** and the
graph refresh at **02:00** every night inside their containers.

The UI will be available at `http://localhost:8501` with real recommendations
from the sample data.

---

## 5  MCP Tools Available

The FastMCP registry (`mcp_book_server.py`) exposes these tools:

| Tool | Function | Rate Limit |
|------|----------|------------|
| `search_catalog` | Vector keyword search | None |
| `enrich_book_metadata` | Google Books â†’ Open Library â†’ readability | 2 rpm GB, 4 rpm OL |
| `get_student_reading_level` | Compute reading level from history | None |
| `find_similar_students` | Query student similarity graph | None |
| `get_book_recommendations_for_group` | Group-based recommendations | None |

---

## 6  ðŸš€ New nightly workers

| Time (UTC) | Container | Function | Worstâ€‘case CPU |
|------------|-----------|----------|---------------|
| 01:00      | book_enrichment_worker | fill page_count, publication_year, difficulty_band | <15 s |
| 02:00      | graph_refresher        | rebuild student similarity & clusters            | <30 s |

Add to `.env`:

```
SIMILARITY_THRESHOLD=0.75
HALF_LIFE_DAYS=45
```

---

## 7  Oneâ€‘liner setup & run commands

```bash
# 1. bootstrap poetry & deps
cd "C:\Users\Dan Guilliams\OneDrive\Code Projects\book_recommendation_engine"
poetry env use 3.11
poetry install  # root has no pyproject, but subâ€‘modules do; Poetry will flatten

# 2. copy env template
cp .env.template .env

# 3. build & run whole stack
docker compose up --build
``` 
